{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKx3VPzmBHSf"
      },
      "source": [
        "# <center>**ProBASS: a language model with sequence and structural features for predicting the effect of mutations on binding affinity**</center>\n",
        "---\n",
        "Here we introduce a model (ProBASS) which is fine-tuned, incorporating features derived from both Protein Language models ESM-2 and ESM-IF1.This model is designed for the prediction of ddGbind values, which serve as indicators of both the sequence and structural attributes of the mutated protein complexes.\n",
        "\n",
        "The model is an efficient way to predict the effect of mutations on protein binding affinity.\n",
        "\n",
        "---\n",
        "\n",
        "**Instructions for users on how to provide the PDB ID of the protein complex and the CSV file which contains the mutation information to Probass**\n",
        "\n",
        "Please input the \"PDB ID\" of the Protein complex under the subcategory Input Data which is required to calculate the binding affinity of the mutations.\n",
        "\n",
        "The user can specify the desired mutations for binding affinity calculation by providing the informations in the proper subcategory. This should include  'Mutated_chain', 'Partner_chain', 'Wild_type', 'Position', and 'Mutation'.\n",
        "\n",
        "The 'Mutated_chain' and 'Partner_chain' define the interface of the protein complex. 'Wild_type' refers to the original amino acid in the protein complex, 'Position' indicates the location of the desired mutation, and 'Mutation' specifies the amino acid the user wishes to substitute for the wild type.\n",
        "\n",
        "**Instructions for using this Colab notebook**\n",
        "\n",
        "Two options are possible for uploading the protein complex structure.\n",
        "\n",
        "1)\t**The complex structure is downloaded directly from the PDB**. Please input the \"PDB ID\" of the Protein complex.\n",
        "\n",
        "\n",
        "2)\t**The complex structure is uploaded from the user’s computer**. To enable users to upload their own complex, kindly remove the comment symbols (#) from all lines in the section labeled \"Uploading the complex instead of PDB ID\". Once uncommented, the user can upload their desired complex upon execution. **Before execution of the program**, The file that you are uploading should be named as a pdb file: 4 letter code with a pdb extension (for example, 3OTJ.pdb). The same pdb file should be specified below under PDB ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3k0uM_5fN9K"
      },
      "source": [
        "# Environment Set up for **ProBASS:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngtlA-3ygDxe"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch-geometric\n",
        "!pip install biotite==0.33.0\n",
        "!pip install catboost\n",
        "!pip install git+https://github.com/facebookresearch/esm.git\n",
        "!pip install requests\n",
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_kHuX4TspGw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import catboost as cb\n",
        "import torch\n",
        "import esm\n",
        "import scipy\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "import requests\n",
        "from Bio.PDB import PDBParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsfKhaV9plmm"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "cd /content/\n",
        "\n",
        "if [ ! -f ProBASS ]; then\n",
        "\n",
        "\n",
        "    # delete the Cold-scanner/ directory if it already exists\n",
        "    if [ -d \"ProBASS/\" ]; then\n",
        "        rm -rf ProBASS/\n",
        "    fi\n",
        "\n",
        "    # download model\n",
        "    git clone https://github.com/sagagugit/ProBASS --quiet\n",
        "    touch ProBASS\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slMOUZcHMjcR"
      },
      "source": [
        "#Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxVZYrF9gi2p"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# from contextlib import redirect_stdout\n",
        "\n",
        "# try:\n",
        "#     from google.colab import drive\n",
        "\n",
        "#     with redirect_stdout(open(os.devnull, 'w')):\n",
        "#         drive.mount('/content/drive')\n",
        "\n",
        "#     from google.colab import files\n",
        "\n",
        "\n",
        "#     print(\"Please upload the .pdb file\")\n",
        "\n",
        "\n",
        "#     uploaded = files.upload()\n",
        "# except FileNotFoundError:\n",
        "#     print(\"ERROR: \\n Uploading was not successful. Please restart and try to upload the complex again.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_CyrX8RlilBx"
      },
      "outputs": [],
      "source": [
        "#@title PDB ID\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive, files\n",
        "import contextlib\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "PDB = '3OTJ' #@param {type:\"string\"}\n",
        "Mutated_chain = 'I' #@param {type:\"string\"}\n",
        "Partner_chain = 'E' #@param {type:\"string\"}\n",
        "Wild_type = 'T' #@param {type:\"string\"}\n",
        "Position = 11 #@param {type:\"integer\"}\n",
        "Mutation = 'P' #@param {type:\"string\"}\n",
        "\n",
        "pdb_file_path = f'/content/{PDB}.pdb'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b4dxngwJ2QA"
      },
      "source": [
        "#Selecting Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q647f5cQiqYQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd ProBASS\n",
        "!cp /content/Input.csv /content/ProBASS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IwIHN76la03"
      },
      "source": [
        "# Extracting embeddings from ESM2 and ESM-IF1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRvtBTBxnYUk"
      },
      "source": [
        "# Extracting Fasta files for wild type, partner chain and mutated PPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o7uWQFbrnrSX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "PDB_code = PDB\n",
        "\n",
        "url = f'http://www.rcsb.org/pdb/download/downloadFile.do?fileFormat=pdb&structureId={PDB_code}'\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open(f'{PDB_code}.pdb', 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'{PDB_code}.pdb has been downloaded successfully.')\n",
        "else:\n",
        "    print(f'Failed to download {PDB_code}.pdb. Status code: {response.status_code}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjpHiKgIjjPk"
      },
      "outputs": [],
      "source": [
        "from Bio.PDB import PDBParser\n",
        "\n",
        "RESIDUE_NAME_TO_LETTER = {\n",
        "    'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',\n",
        "    'GLU': 'E', 'GLN': 'Q', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
        "    'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',\n",
        "    'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V'\n",
        "}\n",
        "\n",
        "try:\n",
        "    PDB_code = PDB\n",
        "    pdb_file = f'{PDB_code}.pdb'\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure(PDB_code, pdb_file)\n",
        "\n",
        "    def extract_sequence_and_check_gaps(chain_id):\n",
        "        sequence = []\n",
        "        start_residue_number = None\n",
        "        previous_resnum = None  # Track the previous residue number to check for gaps\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                if chain.get_id() == chain_id:\n",
        "                    for residue in chain:\n",
        "                        # Exclude heteroatoms (HETATM entries)\n",
        "                        if residue.get_id()[0] != ' ':\n",
        "                            continue\n",
        "\n",
        "                        resname = residue.get_resname()\n",
        "                        resnum = residue.get_id()[1]  # Extract the residue number\n",
        "\n",
        "                        # Check for gaps in the main chain\n",
        "                        if previous_resnum is not None and resnum != previous_resnum + 1:\n",
        "                            raise ValueError(f\"Chain {chain_id} in {PDB_code} has a gap between residues {previous_resnum} and {resnum}.\")\n",
        "\n",
        "                        if start_residue_number is None:\n",
        "                            start_residue_number = resnum\n",
        "                        if resname in RESIDUE_NAME_TO_LETTER:\n",
        "                            sequence.append(RESIDUE_NAME_TO_LETTER[resname])\n",
        "                        previous_resnum = resnum  # Update the previous residue number\n",
        "        return ''.join(sequence), start_residue_number\n",
        "\n",
        "    def adjust_positions(mutated_chain_id, position):\n",
        "        _, start_residue = extract_sequence_and_check_gaps(mutated_chain_id)\n",
        "        return position - start_residue + 1\n",
        "\n",
        "    def apply_mutation(sequence, position, new_residue):\n",
        "        sequence_list = list(sequence)\n",
        "        sequence_list[position - 1] = new_residue\n",
        "        return ''.join(sequence_list)\n",
        "\n",
        "    # Using the provided inputs directly\n",
        "    mutated_chain_id = Mutated_chain\n",
        "    partner_chain_id = Partner_chain\n",
        "    mutation_position = Position\n",
        "    new_residue = Mutation.upper()  # Ensure the mutation is uppercase\n",
        "\n",
        "    # Extract sequences and check for gaps in the main chain\n",
        "    mutated_sequence, mutated_start_residue = extract_sequence_and_check_gaps(mutated_chain_id)\n",
        "    partner_sequence, _ = extract_sequence_and_check_gaps(partner_chain_id)\n",
        "\n",
        "    # Adjust mutation position and apply mutation\n",
        "    adjusted_position = adjust_positions(mutated_chain_id, mutation_position)\n",
        "    mutated_sequence = apply_mutation(mutated_sequence, adjusted_position, new_residue)\n",
        "\n",
        "    # Write sequences to FASTA files\n",
        "    with open(f'{PDB_code}_wild.fasta', 'w') as f:\n",
        "        f.write(f'> {PDB_code}_wild\\n{mutated_sequence}\\n')\n",
        "\n",
        "    with open(f'{PDB_code}_partner.fasta', 'w') as f:\n",
        "        f.write(f'> {PDB_code}_partner\\n{partner_sequence}\\n')\n",
        "\n",
        "except ValueError as ve:\n",
        "    print(\"\\033[1mERROR MESSAGE:!!!\\033[0m\\nThe PDB file contains broken chains.\")\n",
        "    print(f\"Details: {ve}\")\n",
        "except Exception as e:\n",
        "    print(\"\\033[1mERROR MESSAGE:!!!\\033[0m\\nPlease verify that the inputs are properly formatted and that the mutation information is accurate.\")\n",
        "    print(f\"Exception details: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tMZMuaJXjonO"
      },
      "outputs": [],
      "source": [
        "PDB_code = PDB\n",
        "\n",
        "# Helper function to read a FASTA file\n",
        "def read_fasta(fasta_file):\n",
        "    \"\"\"Reads a FASTA file and returns the sequence.\"\"\"\n",
        "    with open(fasta_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    return ''.join(line.strip() for line in lines[1:])\n",
        "\n",
        "# Load the wild-type sequence from the FASTA file\n",
        "wild_sequence = read_fasta(f'{PDB_code}_wild.fasta')\n",
        "\n",
        "# Helper function to extract residue numbers from a PDB file\n",
        "def extract_residue_numbers(pdb_file, chain_id):\n",
        "    \"\"\"Extracts residue numbers for a specific chain from a PDB file.\"\"\"\n",
        "    from Bio.PDB import PDBParser\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure(PDB_code, pdb_file)\n",
        "\n",
        "    residue_numbers = []\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            if chain.get_id() == chain_id:\n",
        "                for residue in chain:\n",
        "                    residue_numbers.append(residue.get_id()[1])\n",
        "    return residue_numbers\n",
        "\n",
        "# Helper function to map a PDB residue position to its index in the sequence\n",
        "def pdb_position_to_index(pdb_residue_numbers, pdb_position):\n",
        "    \"\"\"Finds the sequence index for a given PDB residue position.\"\"\"\n",
        "    try:\n",
        "        return pdb_residue_numbers.index(pdb_position)\n",
        "    except ValueError:\n",
        "        print(f\"Warning: Position {pdb_position} not found in the PDB file.\")\n",
        "        return None\n",
        "\n",
        "# Extract residue numbers for the mutated chain\n",
        "pdb_residue_numbers = extract_residue_numbers(f'{PDB_code}.pdb', Mutated_chain)\n",
        "\n",
        "# Prepare the mutated sequence\n",
        "mutated_sequence = list(wild_sequence)\n",
        "\n",
        "# Apply the mutation\n",
        "idx = pdb_position_to_index(pdb_residue_numbers, Position)\n",
        "if idx is not None and 0 <= idx < len(mutated_sequence):\n",
        "    mutated_sequence[idx] = Mutation.upper()  # Ensure mutation is uppercase\n",
        "    mutated_sequence_str = ''.join(mutated_sequence)\n",
        "\n",
        "    # Prepare FASTA entry\n",
        "    fasta_header = f'> {PDB_code}_{Position}{Mutation.upper()}\\n'\n",
        "    fasta_entry = fasta_header + mutated_sequence_str + '\\n'\n",
        "\n",
        "    # Write to a FASTA file\n",
        "    with open(f'{PDB_code}.fasta', 'w') as f:\n",
        "        f.write(fasta_entry)\n",
        "else:\n",
        "    print(\"ERROR: Mutation position is out of bounds or not found in the PDB residue numbers.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOspFrP_qUhl"
      },
      "source": [
        "# Extract sequence embeddings and Structural embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEMbn79PqkWj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Define the PDB code\n",
        "PDB_code = PDB\n",
        "\n",
        "# Extract embeddings using `esm2_t33_650M_UR50D` for the given FASTA files\n",
        "!python extract.py esm2_t33_650M_UR50D {PDB}.fasta {PDB}_esm2 --repr_layers 0 32 33 --include mean per_tok\n",
        "!python extract.py esm2_t33_650M_UR50D {PDB}_wild.fasta {PDB}_esm2_wild --repr_layers 0 32 33 --include mean per_tok\n",
        "!python extract.py esm2_t33_650M_UR50D {PDB}_partner.fasta {PDB}_esm2_partner --repr_layers 0 32 33 --include mean per_tok\n",
        "\n",
        "# Load the pretrained ESM model for inverse folding\n",
        "import esm\n",
        "import numpy as np\n",
        "from esm.inverse_folding.util import load_structure\n",
        "from esm.inverse_folding.multichain_util import (\n",
        "    extract_coords_from_complex, get_encoder_output_for_complex\n",
        ")\n",
        "\n",
        "model, alphabet = esm.pretrained.esm_if1_gvp4_t16_142M_UR50()\n",
        "model = model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Load the structure using the PDB file\n",
        "fpath = f\"{PDB_code}.pdb\"\n",
        "chain_ids = [Mutated_chain, Partner_chain]\n",
        "\n",
        "structure = load_structure(fpath, chain_ids)\n",
        "\n",
        "# Extract coordinates and native sequences for the chains\n",
        "coords, native_seqs = extract_coords_from_complex(structure)\n",
        "\n",
        "print(f\"Loaded chains: {list(coords.keys())}\\n\")\n",
        "\n",
        "# Print native sequences for the mutated and partner chains\n",
        "for chain_id in chain_ids:\n",
        "    print(f\"Chain {chain_id} native sequence:\")\n",
        "    print(native_seqs[chain_id])\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Generate encoder output for the mutated chain\n",
        "rep = get_encoder_output_for_complex(model, alphabet, coords, Mutated_chain)\n",
        "\n",
        "print(f\"Shape of encoder output for chain {Mutated_chain}: {rep.shape}\")\n",
        "\n",
        "# Save the representation as a NumPy file\n",
        "numpy_rep = rep.detach().numpy()\n",
        "np.savez(f\"inverse_{PDB_code}.npz\", data=numpy_rep)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OagSSYQMrRLK"
      },
      "source": [
        "# Run ProBASS to predict the ΔΔG values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qa-uEhrrw1V"
      },
      "outputs": [],
      "source": [
        "PDBS = PDB_code = [PDB]\n",
        "\n",
        "def exctracting_embeddings_esm2(pdb):\n",
        "    mutations2= []\n",
        "    Xs2 = []\n",
        "    for header2, _seq2 in esm.data.read_fasta(FASTA_PATH2):\n",
        "        scaled_effect2 = header2.split('|')[-1]\n",
        "        mutations2.append(scaled_effect2)\n",
        "        fn = f'{EMB_PATH2}/{header2[1:]}.pt'\n",
        "        embs2 = torch.load(fn)\n",
        "        Xs2.append(embs2['representations'][33])\n",
        "    Xs2 = torch.stack(Xs2, dim=0).numpy()\n",
        "\n",
        "    return Xs2, mutations2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def exctracting_embeddings_esm2_wild(pdb):\n",
        "    mutations2_w= []\n",
        "    Xs2_w = []\n",
        "    for header2, _seq2 in esm.data.read_fasta(FASTA_PATH2_w):\n",
        "        scaled_effect2_w = header2.split('|')[-1]\n",
        "        mutations2_w.append(scaled_effect2_w)\n",
        "        fn = f'{EMB_PATH2_w}/{header2[1:]}.pt'\n",
        "        embs2 = torch.load(fn)\n",
        "        Xs2_w.append(embs2['representations'][33])\n",
        "    Xs2_w = torch.stack(Xs2_w, dim=0).numpy()\n",
        "\n",
        "    return Xs2_w\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def exctracting_embeddings_esm2_bind(pdb):\n",
        "    mutations2_b= []\n",
        "    Xs2_b = []\n",
        "    for header2, _seq2 in esm.data.read_fasta(FASTA_PATH2_b):\n",
        "        scaled_effect2_b = header2.split('|')[-1]\n",
        "        mutations2_b.append(scaled_effect2_b)\n",
        "        fn = f'{EMB_PATH2_b}/{header2[1:]}.pt'\n",
        "        embs2 = torch.load(fn)\n",
        "        Xs2_b.append(embs2['representations'][33])\n",
        "    Xs2_b = torch.stack(Xs2_b, dim=0).numpy()\n",
        "\n",
        "    return Xs2_b\n",
        "\n",
        "def exctracting_embeddings_1f(pdb):\n",
        "    temp= np.load(inverse_path)\n",
        "    inverse= temp['data']\n",
        "\n",
        "\n",
        "    average_mean_embedding = np.mean(inverse, axis=0)\n",
        "    average_mean_embedding.shape\n",
        "    inverse_mean_reshape = average_mean_embedding.reshape([1, 512])\n",
        "    inverse_mean_reshape.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return inverse_mean_reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vouJu42j-Un"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "ddg_values = []\n",
        "embeddings = []\n",
        "for pdb in PDBS:\n",
        "    FASTA_PATH = \"/content/ProBASS/{}.fasta\".format(pdb)\n",
        "    EMB_PATH = \"/content/ProBASS/{}_1V\".format(pdb)\n",
        "    FASTA_PATH2 = \"/content/ProBASS/{}.fasta\".format(pdb)\n",
        "    EMB_PATH2 = \"/content/ProBASS/{}_esm2\".format(pdb)\n",
        "    FASTA_PATH_w = \"/content/ProBASS/{}_wild.fasta\".format(pdb)\n",
        "    EMB_PATH_w = \"/content/ProBASS/{}_1V_wild\".format(pdb)\n",
        "    FASTA_PATH2_w = \"/content/ProBASS/{}_wild.fasta\".format(pdb)\n",
        "    EMB_PATH2_w = \"/content/ProBASS/{}_esm2_wild\".format(pdb)\n",
        "    FASTA_PATH_b = \"/content/ProBASS/{}_partner.fasta\".format(pdb)\n",
        "    EMB_PATH_b = \"/content/ProBASS/{}_1V_partner\".format(pdb)\n",
        "    FASTA_PATH2_b = \"/content/ProBASS/{}_partner.fasta\".format(pdb)\n",
        "    EMB_PATH2_b = \"/content/ProBASS/{}_esm2_partner\".format(pdb)\n",
        "    inverse_path = '/content/ProBASS/inverse_{}.npz'.format(pdb)\n",
        "    csv_path = \"/content/ProBASS/{}.csv\".format(pdb)\n",
        "    Xs2, mutations2= exctracting_embeddings_esm2(pdb)\n",
        "    Xs2_w= exctracting_embeddings_esm2_wild(pdb)\n",
        "    Xs2_w=np.tile(Xs2_w, (len(Xs2), 1, 1))\n",
        "    Xs2_b=exctracting_embeddings_esm2_bind(pdb)\n",
        "    Xs2_b=np.tile(Xs2_b, (len(Xs2), 1, 1))\n",
        "    inverse=exctracting_embeddings_1f(pdb)\n",
        "    inverse=np.tile(inverse, (len(Xs2), 1))\n",
        "    mutant_and_partner_together_esm2 = np.concatenate([Xs2_b, Xs2], axis =1)\n",
        "\n",
        "    wild_type_and_partner_together_esm2 = np.concatenate([Xs2_b, Xs2_w], axis =1)\n",
        "    mutant_and_partner_together_esm2_mean=np.mean(mutant_and_partner_together_esm2, axis=1)\n",
        "    wild_type_and_partner_together_esm2_mean=np.mean(wild_type_and_partner_together_esm2, axis=1)\n",
        "    ddg_1v = np.subtract(mutant_and_partner_together_esm2_mean, wild_type_and_partner_together_esm2_mean)\n",
        "\n",
        "    ddg_esm2_with_inverse = np.concatenate([ddg_1v, inverse], axis =1)\n",
        "    embeddings.append(ddg_esm2_with_inverse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fb0ixxAVkBm9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "ddg_length = len(embeddings[0])\n",
        "ddg_values = [0] * ddg_length\n",
        "\n",
        "\n",
        "flattened_list = ddg_values\n",
        "\n",
        "\n",
        "extracted_array = embeddings[0]\n",
        "Xs_test = extracted_array\n",
        "ys_test = flattened_list\n",
        "\n",
        "np.savez('test.npz', data=Xs_test, label=ys_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w10iJgAKkDkw"
      },
      "outputs": [],
      "source": [
        "temp = np.load('test.npz')\n",
        "X_test, test_y = temp['data'], temp['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tCwzqKfkFXM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import catboost as cb\n",
        "\n",
        "# Assuming the following inputs are already defined in the previous cells:\n",
        "# `Wild_type`, `Position`, `Mutation`, and `X_test` (test features for the model).\n",
        "\n",
        "# Ensure that `Wild_type`, `Position`, and `Mutation` are defined\n",
        "try:\n",
        "    # Combine inputs to create the mutation string\n",
        "    mutation_string = Wild_type + str(Position) + Mutation.upper()\n",
        "\n",
        "    # Load the trained CatBoost model\n",
        "    model = cb.CatBoostRegressor()\n",
        "    model.load_model('Probass_model.cbm')\n",
        "\n",
        "    # Generate predictions using the model\n",
        "    ypred = model.predict(X_test)\n",
        "\n",
        "    # Prepare a DataFrame with mutation information and predicted values\n",
        "    predicted_df = pd.DataFrame({\n",
        "        'Mutation': [mutation_string],  # Single mutation string\n",
        "        'predicted_value ΔΔG kcal/mol': ypred\n",
        "    })\n",
        "\n",
        "    # Save the predictions to a CSV file\n",
        "    predicted_df.to_csv('predicted_values.csv', index=False)\n",
        "\n",
        "except NameError as e:\n",
        "    print(\"\\033[1mERROR MESSAGE:!!!\\033[0m\")\n",
        "    print(f\"Missing input: {e}. Ensure all required variables are defined in previous cells.\")\n",
        "except Exception as e:\n",
        "    print(\"\\033[1mERROR MESSAGE:!!!\\033[0m\")\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9npsnXKnHou"
      },
      "source": [
        "# Download Predicted Binding Affinintes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtZdV_XnMRI"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "files.download('predicted_values.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "I3k0uM_5fN9K",
        "3b4dxngwJ2QA",
        "KRvtBTBxnYUk",
        "oOspFrP_qUhl",
        "OagSSYQMrRLK",
        "R9npsnXKnHou"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}