{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKx3VPzmBHSf"
      },
      "source": [
        "# <center>**ProBASS: a language model with sequence and structural features for predicting the effect of mutations on binding affinity**</center>\n",
        "---\n",
        "Here we introduce a model (ProBASS) which is fine-tuned, incorporating features derived from both Protein Language models ESM-2 and ESM-IF1.This model is designed for the prediction of ddGbind values, which serve as indicators of both the sequence and structural attributes of the mutated protein complexes.\n",
        "\n",
        "The model is an efficient way to predict the effect of mutations on protein binding affinity.\n",
        "\n",
        "---\n",
        "\n",
        "**Instructions for users on how to provide the PDB ID of the protein complex and necessary parameters**\n",
        "\n",
        "Please input the \"PDB ID\" of the Protein complex under the subcategory Input Data which is required to calculate the binding affinity of the mutations.\n",
        "\n",
        "The user can specify the desired mutations for binding affinity calculation by providing the informations in the proper subcategory. This should include  'Mutated_chain', 'Partner_chain', 'Wild_type', 'Position', and 'Mutation'.\n",
        "\n",
        "The 'Mutated_chain' and 'Partner_chain' define the interface of the protein complex. 'Wild_type' refers to the original amino acid in the protein complex, 'Position' indicates the location of the desired mutation, and 'Mutation' specifies the amino acid the user wishes to substitute for the wild type.\n",
        "\n",
        "**Instructions for using this Colab notebook**\n",
        "\n",
        "Two options are possible for uploading the protein complex structure.\n",
        "\n",
        "1)\t**The complex structure is downloaded directly from the PDB**. Please input the \"PDB ID\" of the Protein complex.\n",
        "\n",
        "\n",
        "2)\t**The complex structure is uploaded from the user’s computer**. To enable users to upload their own complex, kindly remove the comment symbols (#) from all lines in the section labeled \"Uploading the complex instead of PDB ID\". Once uncommented, the user can upload their desired complex upon execution. **Before execution of the program**, The file that you are uploading should be named as a pdb file: 4 letter code with a pdb extension (for example, 3OTJ.pdb). The same pdb file should be specified below under PDB ID.\n",
        "\n",
        "Please click \"Restart session and run all\" after each execution even for the same PDB ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3k0uM_5fN9K"
      },
      "source": [
        "# Environment Set up for **ProBASS:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ngtlA-3ygDxe"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch-geometric\n",
        "!pip install biotite==0.33.0\n",
        "!pip install catboost\n",
        "!pip install git+https://github.com/facebookresearch/esm.git\n",
        "!pip install requests\n",
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I_kHuX4TspGw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import catboost as cb\n",
        "import torch\n",
        "import esm\n",
        "import scipy\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "import requests\n",
        "from Bio.PDB import PDBParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EsfKhaV9plmm"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "cd /content/\n",
        "\n",
        "if [ ! -f ProBASS ]; then\n",
        "\n",
        "\n",
        "    # delete the Cold-scanner/ directory if it already exists\n",
        "    if [ -d \"ProBASS/\" ]; then\n",
        "        rm -rf ProBASS/\n",
        "    fi\n",
        "\n",
        "    # download model\n",
        "    git clone https://github.com/sagagugit/ProBASS --quiet\n",
        "    touch ProBASS\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd ProBASS"
      ],
      "metadata": {
        "id": "ZXg1E8C9dcGR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slMOUZcHMjcR"
      },
      "source": [
        "#Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KxVZYrF9gi2p"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# from contextlib import redirect_stdout\n",
        "\n",
        "# try:\n",
        "#     from google.colab import drive\n",
        "\n",
        "#     with redirect_stdout(open(os.devnull, 'w')):\n",
        "#         drive.mount('/content/drive')\n",
        "\n",
        "#     from google.colab import files\n",
        "\n",
        "\n",
        "#     print(\"Please upload the .pdb file\")\n",
        "\n",
        "\n",
        "#     uploaded = files.upload()\n",
        "# except FileNotFoundError:\n",
        "#     print(\"ERROR: \\n Uploading was not successful. Please restart and try to upload the complex again.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_CyrX8RlilBx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title PDB ID\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive, files\n",
        "import contextlib\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "PDB = '3OTJ' #@param {type:\"string\"}\n",
        "Mutated_chain = 'I' #@param {type:\"string\"}\n",
        "Partner_chain = 'E' #@param {type:\"string\"}\n",
        "Wild_type = 'T' #@param {type:\"string\"}\n",
        "Position = 12 #@param {type:\"integer\"}\n",
        "Mutation = 'P' #@param {type:\"string\"}\n",
        "\n",
        "pdb_file_path = f'/content/{PDB}.pdb'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b4dxngwJ2QA"
      },
      "source": [
        "#Selecting Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IwIHN76la03"
      },
      "source": [
        "# Extracting embeddings from ESM2 and ESM-IF1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRvtBTBxnYUk"
      },
      "source": [
        "# Extracting Fasta files for wild type, partner chain and mutated PPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o7uWQFbrnrSX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "PDB_code = PDB\n",
        "\n",
        "url = f'http://www.rcsb.org/pdb/download/downloadFile.do?fileFormat=pdb&structureId={PDB_code}'\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open(f'{PDB_code}.pdb', 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f'{PDB_code}.pdb has been downloaded successfully.')\n",
        "else:\n",
        "    print(f'Failed to download {PDB_code}.pdb. Status code: {response.status_code}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TjpHiKgIjjPk"
      },
      "outputs": [],
      "source": [
        "from Bio.PDB import PDBParser\n",
        "\n",
        "RESIDUE_NAME_TO_LETTER = {\n",
        "    'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',\n",
        "    'GLU': 'E', 'GLN': 'Q', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
        "    'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',\n",
        "    'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V'\n",
        "}\n",
        "\n",
        "try:\n",
        "    PDB_code = PDB\n",
        "    pdb_file = f'{PDB_code}.pdb'\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure(PDB_code, pdb_file)\n",
        "\n",
        "    def extract_sequence_and_start(chain_id):\n",
        "        sequence = []\n",
        "        start_residue_number = None\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                if chain.get_id() == chain_id:\n",
        "                    for residue in chain:\n",
        "                        resname = residue.get_resname()\n",
        "                        resnum = residue.get_id()[1]\n",
        "                        if start_residue_number is None:\n",
        "                            start_residue_number = resnum\n",
        "                        if resname in RESIDUE_NAME_TO_LETTER:\n",
        "                            sequence.append(RESIDUE_NAME_TO_LETTER[resname])\n",
        "        return ''.join(sequence), start_residue_number\n",
        "\n",
        "    def adjust_positions(mutated_chain_id, position):\n",
        "        _, start_residue = extract_sequence_and_start(mutated_chain_id)\n",
        "        return position - start_residue + 1\n",
        "\n",
        "    def apply_mutation(sequence, position, new_residue):\n",
        "        sequence_list = list(sequence)\n",
        "        sequence_list[position - 1] = new_residue\n",
        "        return ''.join(sequence_list)\n",
        "\n",
        "    # Using the provided inputs directly\n",
        "    mutated_chain_id = Mutated_chain\n",
        "    partner_chain_id = Partner_chain\n",
        "    mutation_position = Position\n",
        "    new_residue = Mutation.upper()  # Ensure the mutation is uppercase\n",
        "\n",
        "    # Extract the original sequences for the wild-type\n",
        "    wild_sequence, _ = extract_sequence_and_start(mutated_chain_id)\n",
        "    partner_sequence, _ = extract_sequence_and_start(partner_chain_id)\n",
        "\n",
        "    # Save the wild-type sequence to a FASTA file\n",
        "    with open(f'{PDB_code}_wild.fasta', 'w') as f:\n",
        "        f.write(f'> {PDB_code}_wild\\n{wild_sequence}\\n')\n",
        "\n",
        "    with open(f'{PDB_code}_partner.fasta', 'w') as f:\n",
        "        f.write(f'> {PDB_code}_partner\\n{partner_sequence}\\n')\n",
        "\n",
        "    # Apply the mutation to the wild-type sequence\n",
        "    adjusted_position = adjust_positions(mutated_chain_id, mutation_position)\n",
        "    mutated_sequence = apply_mutation(wild_sequence, adjusted_position, new_residue)\n",
        "\n",
        "    # Save the mutated sequence to a new file (if needed)\n",
        "    with open(f'{PDB_code}.fasta', 'w') as f:\n",
        "        f.write(f'> {PDB_code}_mutated\\n{mutated_sequence}\\n')\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\033[1mERROR MESSAGE:!!!\\033[0m\\nPlease verify that the inputs are properly formatted and that the mutation information is accurate.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tMZMuaJXjonO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOspFrP_qUhl"
      },
      "source": [
        "# Extract sequence embeddings and Structural embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AEMbn79PqkWj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Define the PDB code\n",
        "PDB_code = PDB\n",
        "\n",
        "# Extract embeddings using `esm2_t33_650M_UR50D` for the given FASTA files\n",
        "!python extract.py esm2_t33_650M_UR50D {PDB}.fasta {PDB}_esm2 --repr_layers 0 32 33 --include mean per_tok\n",
        "!python extract.py esm2_t33_650M_UR50D {PDB}_wild.fasta {PDB}_esm2_wild --repr_layers 0 32 33 --include mean per_tok\n",
        "!python extract.py esm2_t33_650M_UR50D {PDB}_partner.fasta {PDB}_esm2_partner --repr_layers 0 32 33 --include mean per_tok\n",
        "\n",
        "# Load the pretrained ESM model for inverse folding\n",
        "import esm\n",
        "import numpy as np\n",
        "from esm.inverse_folding.util import load_structure\n",
        "from esm.inverse_folding.multichain_util import (\n",
        "    extract_coords_from_complex, get_encoder_output_for_complex\n",
        ")\n",
        "\n",
        "model, alphabet = esm.pretrained.esm_if1_gvp4_t16_142M_UR50()\n",
        "model = model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Load the structure using the PDB file\n",
        "fpath = f\"{PDB_code}.pdb\"\n",
        "chain_ids = [Mutated_chain, Partner_chain]\n",
        "\n",
        "structure = load_structure(fpath, chain_ids)\n",
        "\n",
        "# Extract coordinates and native sequences for the chains\n",
        "coords, native_seqs = extract_coords_from_complex(structure)\n",
        "\n",
        "print(f\"Loaded chains: {list(coords.keys())}\\n\")\n",
        "\n",
        "# Print native sequences for the mutated and partner chains\n",
        "for chain_id in chain_ids:\n",
        "    print(f\"Chain {chain_id} native sequence:\")\n",
        "    print(native_seqs[chain_id])\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Generate encoder output for the mutated chain\n",
        "rep = get_encoder_output_for_complex(model, alphabet, coords, Mutated_chain)\n",
        "\n",
        "print(f\"Shape of encoder output for chain {Mutated_chain}: {rep.shape}\")\n",
        "\n",
        "# Save the representation as a NumPy file\n",
        "numpy_rep = rep.detach().numpy()\n",
        "np.savez(f\"inverse_{PDB_code}.npz\", data=numpy_rep)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OagSSYQMrRLK"
      },
      "source": [
        "# Run ProBASS to predict the ΔΔG values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2qa-uEhrrw1V"
      },
      "outputs": [],
      "source": [
        "PDBS = PDB_code = [PDB]\n",
        "\n",
        "def exctracting_embeddings_esm2(pdb):\n",
        "    mutations2= []\n",
        "    Xs2 = []\n",
        "    for header2, _seq2 in esm.data.read_fasta(FASTA_PATH2):\n",
        "        scaled_effect2 = header2.split('|')[-1]\n",
        "        mutations2.append(scaled_effect2)\n",
        "        fn = f'{EMB_PATH2}/{header2[1:]}.pt'\n",
        "        embs2 = torch.load(fn)\n",
        "        Xs2.append(embs2['representations'][33])\n",
        "    Xs2 = torch.stack(Xs2, dim=0).numpy()\n",
        "    print(Xs2)\n",
        "\n",
        "    return Xs2, mutations2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def exctracting_embeddings_esm2_wild(pdb):\n",
        "    mutations2_w= []\n",
        "    Xs2_w = []\n",
        "    for header2, _seq2 in esm.data.read_fasta(FASTA_PATH2_w):\n",
        "        scaled_effect2_w = header2.split('|')[-1]\n",
        "        mutations2_w.append(scaled_effect2_w)\n",
        "        fn = f'{EMB_PATH2_w}/{header2[1:]}.pt'\n",
        "        embs2 = torch.load(fn)\n",
        "        Xs2_w.append(embs2['representations'][33])\n",
        "    Xs2_w = torch.stack(Xs2_w, dim=0).numpy()\n",
        "\n",
        "    return Xs2_w\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def exctracting_embeddings_esm2_bind(pdb):\n",
        "    mutations2_b= []\n",
        "    Xs2_b = []\n",
        "    for header2, _seq2 in esm.data.read_fasta(FASTA_PATH2_b):\n",
        "        scaled_effect2_b = header2.split('|')[-1]\n",
        "        mutations2_b.append(scaled_effect2_b)\n",
        "        fn = f'{EMB_PATH2_b}/{header2[1:]}.pt'\n",
        "        embs2 = torch.load(fn)\n",
        "        Xs2_b.append(embs2['representations'][33])\n",
        "    Xs2_b = torch.stack(Xs2_b, dim=0).numpy()\n",
        "\n",
        "    return Xs2_b\n",
        "\n",
        "def exctracting_embeddings_1f(pdb):\n",
        "    temp= np.load(inverse_path)\n",
        "    inverse= temp['data']\n",
        "\n",
        "\n",
        "    average_mean_embedding = np.mean(inverse, axis=0)\n",
        "    average_mean_embedding.shape\n",
        "    inverse_mean_reshape = average_mean_embedding.reshape([1, 512])\n",
        "    inverse_mean_reshape.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return inverse_mean_reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8vouJu42j-Un"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "ddg_values = []\n",
        "embeddings = []\n",
        "for pdb in PDBS:\n",
        "    FASTA_PATH = \"/content/ProBASS/{}.fasta\".format(pdb)\n",
        "    EMB_PATH = \"/content/ProBASS/{}_1V\".format(pdb)\n",
        "    FASTA_PATH2 = \"/content/ProBASS/{}.fasta\".format(pdb)\n",
        "    EMB_PATH2 = \"/content/ProBASS/{}_esm2\".format(pdb)\n",
        "    FASTA_PATH_w = \"/content/ProBASS/{}_wild.fasta\".format(pdb)\n",
        "    EMB_PATH_w = \"/content/ProBASS/{}_1V_wild\".format(pdb)\n",
        "    FASTA_PATH2_w = \"/content/ProBASS/{}_wild.fasta\".format(pdb)\n",
        "    EMB_PATH2_w = \"/content/ProBASS/{}_esm2_wild\".format(pdb)\n",
        "    FASTA_PATH_b = \"/content/ProBASS/{}_partner.fasta\".format(pdb)\n",
        "    EMB_PATH_b = \"/content/ProBASS/{}_1V_partner\".format(pdb)\n",
        "    FASTA_PATH2_b = \"/content/ProBASS/{}_partner.fasta\".format(pdb)\n",
        "    EMB_PATH2_b = \"/content/ProBASS/{}_esm2_partner\".format(pdb)\n",
        "    inverse_path = '/content/ProBASS/inverse_{}.npz'.format(pdb)\n",
        "    csv_path = \"/content/ProBASS/{}.csv\".format(pdb)\n",
        "    Xs2, mutations2= exctracting_embeddings_esm2(pdb)\n",
        "    print(Xs2)\n",
        "    Xs2_w= exctracting_embeddings_esm2_wild(pdb)\n",
        "    Xs2_w=np.tile(Xs2_w, (len(Xs2), 1, 1))\n",
        "    Xs2_b=exctracting_embeddings_esm2_bind(pdb)\n",
        "    Xs2_b=np.tile(Xs2_b, (len(Xs2), 1, 1))\n",
        "    inverse=exctracting_embeddings_1f(pdb)\n",
        "    inverse=np.tile(inverse, (len(Xs2), 1))\n",
        "    mutant_and_partner_together_esm2 = np.concatenate([Xs2_b, Xs2], axis =1)\n",
        "\n",
        "    wild_type_and_partner_together_esm2 = np.concatenate([Xs2_b, Xs2_w], axis =1)\n",
        "    mutant_and_partner_together_esm2_mean=np.mean(mutant_and_partner_together_esm2, axis=1)\n",
        "    wild_type_and_partner_together_esm2_mean=np.mean(wild_type_and_partner_together_esm2, axis=1)\n",
        "    ddg_1v = np.subtract(mutant_and_partner_together_esm2_mean, wild_type_and_partner_together_esm2_mean)\n",
        "\n",
        "    ddg_esm2_with_inverse = np.concatenate([ddg_1v, inverse], axis =1)\n",
        "    embeddings.append(ddg_esm2_with_inverse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fb0ixxAVkBm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee2e54d-68ea-4ac4-da5f-9abb2c184bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to 'test.npz'.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ensure `embeddings` is defined and contains valid data\n",
        "try:\n",
        "    # Validate embeddings structure\n",
        "    if not isinstance(embeddings, list) or len(embeddings) == 0:\n",
        "        raise ValueError(\"Embeddings must be a non-empty list.\")\n",
        "\n",
        "    # Extract the first embedding array\n",
        "    extracted_array = np.array(embeddings[0])  # Convert to NumPy array for safety\n",
        "    ddg_length = extracted_array.shape[0]\n",
        "\n",
        "    # Initialize DDG values (default: zeros)\n",
        "    ddg_values = np.zeros(ddg_length)\n",
        "\n",
        "    # Assign test data\n",
        "    Xs_test = extracted_array\n",
        "    ys_test = ddg_values\n",
        "\n",
        "    # Save data and labels to NPZ\n",
        "    np.savez('test.npz', data=Xs_test, label=ys_test)\n",
        "    print(\"Data successfully saved to 'test.npz'.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\033[1mERROR MESSAGE:!!!\\033[0m\")\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w10iJgAKkDkw"
      },
      "outputs": [],
      "source": [
        "temp = np.load('test.npz')\n",
        "X_test, test_y = temp['data'], temp['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-tCwzqKfkFXM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import catboost as cb\n",
        "\n",
        "# Assuming the following inputs are already defined in the previous cells:\n",
        "# `Wild_type`, `Position`, `Mutation`, and `X_test` (test features for the model).\n",
        "\n",
        "# Ensure that `Wild_type`, `Position`, and `Mutation` are defined\n",
        "try:\n",
        "    # Combine inputs to create the mutation string\n",
        "    mutation_string = Wild_type + str(Position) + Mutation.upper()\n",
        "\n",
        "    # Load the trained CatBoost model\n",
        "    model = cb.CatBoostRegressor()\n",
        "    model.load_model('Probass_model.cbm')\n",
        "\n",
        "    # Generate predictions using the model\n",
        "    ypred = model.predict(X_test)\n",
        "\n",
        "    # Prepare a DataFrame with mutation information and predicted values\n",
        "    predicted_df = pd.DataFrame({\n",
        "        'Mutation': [mutation_string],  # Single mutation string\n",
        "        'predicted_value ΔΔG kcal/mol': ypred\n",
        "    })\n",
        "\n",
        "    # Save the predictions to a CSV file\n",
        "    predicted_df.to_csv('predicted_values.csv', index=False)\n",
        "\n",
        "except NameError as e:\n",
        "    print(\"\\033[1mERROR MESSAGE:!!!\\033[0m\")\n",
        "    print(f\"Missing input: {e}. Ensure all required variables are defined in previous cells.\")\n",
        "except Exception as e:\n",
        "    print(\"\\033[1mERROR MESSAGE:!!!\\033[0m\")\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9npsnXKnHou"
      },
      "source": [
        "# Download Predicted Binding Affinintes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gVtZdV_XnMRI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2f588749-925e-4dfe-e331-5cb5b10f30e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de05b027-9c14-4c00-8546-168ee6f88fc6\", \"predicted_values.csv\", 63)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "files.download('predicted_values.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "I3k0uM_5fN9K",
        "KRvtBTBxnYUk",
        "oOspFrP_qUhl",
        "OagSSYQMrRLK",
        "R9npsnXKnHou"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}